#include "al_ext/video/al_VideoDecoder.hpp"

#ifdef WIN32
#define NOMINMAX
#define WIN32_LEAN_AND_MEAN
#include <windows.h>

#else
// #include <pthread.h>
#endif

using namespace al;

void VideoDecoder::init() {
  video_state.format_ctx = nullptr;

  video_state.video_st_idx = -1;
  video_state.video_st = nullptr;
  video_state.video_ctx = nullptr;
  video_state.sws_ctx = nullptr;
  video_state.video_frames = nullptr;
  for (int i = 0; i < 4; ++i) {
    video_state.line_sizes[i] = 0;
  }

  video_state.audio_enabled = true;
  video_state.audio_st_idx = -1;
  video_state.audio_st = nullptr;
  video_state.audio_ctx = nullptr;
  video_state.audio_frames = nullptr;
  video_state.audio_sample_size = 0;
  video_state.audio_channel_size = 0;
  video_state.audio_frame_size = 0;

  video_state.master_sync = MasterSync::AV_SYNC_EXTERNAL;
  video_state.video_clock = 0;
  video_state.audio_clock = 0;
  video_state.master_clock = 0;
  video_state.last_frame_pts = 0;

  video_state.seek_requested = 0;
  video_state.seek_flags = 0;
  video_state.seek_pos = 0;

  video_state.global_quit.store(false);
  video_state.global_pause = false;
  video_state.global_loop = false;
  video_state.global_finished.store(false);
}

bool VideoDecoder::load(const char *url) {
  // open file
  if (avformat_open_input(&video_state.format_ctx, url, NULL, NULL) < 0) {
    std::cerr << "Could not open file: " << url << std::endl;
    return false;
  }

  // retrieve stream information
  if (avformat_find_stream_info(video_state.format_ctx, NULL) < 0) {
    std::cerr << "Could not find stream info: " << url << std::endl;
    return false;
  }

  // print info
  av_dump_format(video_state.format_ctx, 0, url, 0);

  // find video & audio stream
  // TODO: choose stream in case of multiple streams
  for (int i = 0; i < video_state.format_ctx->nb_streams; ++i) {
    if (video_state.format_ctx->streams[i]->codecpar->codec_type ==
            AVMEDIA_TYPE_VIDEO &&
        video_state.video_st_idx < 0) {
      video_state.video_st_idx = i;
      if (video_state.audio_st_idx > 0)
        break;
    }

    if (video_state.format_ctx->streams[i]->codecpar->codec_type ==
            AVMEDIA_TYPE_AUDIO &&
        video_state.audio_st_idx < 0) {
      video_state.audio_st_idx = i;
      if (video_state.video_st_idx > 0)
        break;
    }
  }

  if (video_state.video_st_idx == -1) {
    std::cerr << "Could not find video stream" << std::endl;
    return false;
  } else if (!stream_component_open(&video_state, video_state.video_st_idx)) {
    std::cerr << "Could not open video codec" << std::endl;
    return false;
  }

  if (video_state.audio_st_idx == -1) {
    // no audio stream
    // TODO: consider audio only files
    video_state.audio_enabled = false;
  } else if (video_state.audio_enabled) {
    if (!stream_component_open(&video_state, video_state.audio_st_idx)) {
      std::cerr << "Could not open audio codec" << std::endl;
      return false;
    }

    video_state.audio_frames = &audio_buffer;
  }

  video_state.video_frames = &video_buffer;

  // TODO: add initialization notice to videoapp
  return true;
}

bool VideoDecoder::stream_component_open(VideoState *vs, int stream_index) {
  // check if stream index is valid
  if (stream_index < 0 || stream_index >= vs->format_ctx->nb_streams) {
    std::cerr << "Invalid stream index" << std::endl;
    return false;
  }

  // retrieve codec
  const AVCodec *codec = nullptr;
  codec = avcodec_find_decoder(
      vs->format_ctx->streams[stream_index]->codecpar->codec_id);
  if (!codec) {
    std::cerr << "Unsupported codec" << std::endl;
    return false;
  }

  // retrieve codec context
  AVCodecContext *codecCtx = nullptr;
  codecCtx = avcodec_alloc_context3(codec);
  if (avcodec_parameters_to_context(
          codecCtx, vs->format_ctx->streams[stream_index]->codecpar) != 0) {
    std::cerr << "Could not copy codec context" << std::endl;
    return false;
  }

  // initialize the AVCodecContext to use the given AVCodec
  if (avcodec_open2(codecCtx, codec, NULL) < 0) {
    std::cerr << "Could not open codec" << std::endl;
    return false;
  }

  switch (codecCtx->codec_type) {
  case AVMEDIA_TYPE_AUDIO: {
    vs->audio_st = vs->format_ctx->streams[stream_index];
    vs->audio_ctx = codecCtx;

    // set parameters
    vs->audio_sample_size = av_get_bytes_per_sample(vs->audio_ctx->sample_fmt);
    if (vs->audio_sample_size < 0) {
      std::cerr << "Failed to calculate data size" << std::endl;
      return false;
    }

    vs->audio_channel_size = vs->audio_sample_size * vs->audio_ctx->frame_size;

    vs->audio_frame_size = vs->audio_sample_size * vs->audio_ctx->frame_size *
                           vs->audio_ctx->ch_layout.nb_channels;
  } break;
  case AVMEDIA_TYPE_VIDEO: {
    vs->video_st = vs->format_ctx->streams[stream_index];
    vs->video_ctx = codecCtx;

    // initialize SWS context for software scaling
    vs->sws_ctx = sws_getContext(vs->video_ctx->width, vs->video_ctx->height,
                                 vs->video_ctx->pix_fmt, vs->video_ctx->width,
                                 vs->video_ctx->height, AV_PIX_FMT_GRAY8,
                                 SWS_FAST_BILINEAR, NULL, NULL, NULL);

    av_image_fill_linesizes(vs->line_sizes, AV_PIX_FMT_YUV420P,
                            codecCtx->width);
  } break;
  default: {
    break;
  }
  }

  return true;
}

void VideoDecoder::start() {
  // if threads are already running, close them
  if (decode_thread != nullptr) {
    stop();
  }

  // check if video streams is valid
  if (video_state.video_st != nullptr) {
    decode_thread = new std::thread(decodeThreadFunction, &video_state);
#ifdef WIN32
    // std::cout << "current thread priority: "
    //           << GetThreadPriority(GetCurrentThread()) << std::endl;
    // std::cout << "decode thread priority: "
    //           << GetThreadPriority(decode_thread->native_handle()) <<
    //           std::endl;

    int result = SetThreadPriority(decode_thread->native_handle(),
                                   THREAD_PRIORITY_HIGHEST);
    if (result == 0) {
      std::cerr << "set priority failed" << std::endl;
    } else {
      std::cout << "Decode thread set to NORMAL_PRIORITY_CLASS, "
                   "THREAD_PRIORITY_HIGHEST"
                << std::endl;
    }
// std::cout << "decode thread priority: "
//           << GetThreadPriority(decode_thread->native_handle()) <<
//           std::endl;
#else
    // int policy;
    // sched_param params;
    // if (pthread_getschedparam(decode_thread->native_handle(), &policy,
    //                           &params) != 0) {
    //   std::cerr << "get sched param failed" << std::endl;
    // } else {
    //   std::cout << "policy: " << policy << std::endl;
    //   std::cout << "priority: " << params.sched_priority << std::endl;
    //   params.sched_priority = 0; // sched_get_priority_max(SCHED_FIFO);
    //   int result = pthread_setschedparam(decode_thread->native_handle(),
    //                                      SCHED_FIFO, &params);
    //   if (result != 0) {
    //     std::cerr << "set sched param failed: " << result << std::endl;
    //   } else {
    //     std::cout << "new priority: " << params.sched_priority << std::endl;
    //   }
    // }
#endif
  }

  if (!decode_thread) {
    std::cerr << "Could not start decoding thread" << std::endl;
    stop();
  }
}

void VideoDecoder::decodeThreadFunction(VideoState *vs) {
  // // allocate packet
  AVPacket *packet = av_packet_alloc();
  if (!packet) {
    std::cerr << "Could not allocate packet" << std::endl;
    return;
  }

  // allocate frame
  AVFrame *frame = av_frame_alloc();
  if (!frame) {
    std::cerr << "Could not allocate frame" << std::endl;
    av_packet_free(&packet);
    return;
  }

  // allocate frame
  AVFrame *frameRGB = av_frame_alloc();
  if (!frameRGB) {
    std::cerr << "Could not allocate frameRGB" << std::endl;
    av_frame_free(&frame);
    av_packet_free(&packet);
    return;
  }

  int numBytes = av_image_get_buffer_size(
      AV_PIX_FMT_GRAY8, vs->video_ctx->width, vs->video_ctx->height, 32);
  uint8_t *buffer = (uint8_t *)av_malloc(numBytes * sizeof(uint8_t));

  // Setup pointers and linesize for dst frame and image data buffer
  av_image_fill_arrays(frameRGB->data, frameRGB->linesize, buffer,
                       AV_PIX_FMT_GRAY8, vs->video_ctx->width,
                       vs->video_ctx->height, 32);

  int numBytesY = vs->line_sizes[0] * vs->video_ctx->height;
  int numBytesU = vs->line_sizes[1] * vs->video_ctx->height / 2;
  int numBytesV = vs->line_sizes[2] * vs->video_ctx->height / 2;

  uint8_t *bufferY = (uint8_t *)av_malloc(numBytesY * sizeof(uint8_t));
  uint8_t *bufferU = (uint8_t *)av_malloc(numBytesU * sizeof(uint8_t));
  uint8_t *bufferV = (uint8_t *)av_malloc(numBytesV * sizeof(uint8_t));

  uint8_t *audio_out =
      (uint8_t *)av_malloc(vs->audio_frame_size * sizeof(uint8_t));

  // check global quit flag
  while (!vs->global_quit.load()) {
    // seeking
    if (vs->seek_requested.load()) {
      // std::cout << "seek start" << std::endl;
      int video_stream_index = -1;
      int audio_stream_index = -1;
      int64_t video_seek_target = vs->seek_pos;
      int64_t audio_seek_target = vs->seek_pos;

      if (vs->video_st)
        video_stream_index = vs->video_st_idx;
      if (vs->audio_st && vs->audio_enabled)
        audio_stream_index = vs->audio_st_idx;

      if (video_stream_index >= 0) {
        video_seek_target = av_rescale_q(
            video_seek_target, av_get_time_base_q(),
            vs->format_ctx->streams[video_stream_index]->time_base);
      }
      if (audio_stream_index >= 0) {
        audio_seek_target = av_rescale_q(
            audio_seek_target, av_get_time_base_q(),
            vs->format_ctx->streams[audio_stream_index]->time_base);
      }

      int ret = av_seek_frame(vs->format_ctx, video_stream_index,
                              video_seek_target, vs->seek_flags);
      if (vs->audio_st && vs->audio_enabled)
        ret &= av_seek_frame(vs->format_ctx, audio_stream_index,
                             audio_seek_target, vs->seek_flags);

      if (ret < 0) {
        std::cerr << "Error while seeking" << std::endl;
      } else {
        if (vs->video_st) {
          vs->video_frames->flush();
        }
        if (vs->audio_st && vs->audio_enabled) {
          vs->audio_frames->flush();
        }
        vs->seek_requested.store(false);
      }
      // std::cout << "seek end" << std::endl;
    }

    if (vs->global_finished.load()) {
      al_sleep_nsec(1000000); // 10 ms
      continue;
    }

    // read the next frame
    if (av_read_frame(vs->format_ctx, packet) < 0) {
      // no read error; wait for file
      if (vs->format_ctx->pb->error == 0) {
        vs->global_finished.store(true);
        if (!vs->global_loop) {
          vs->global_quit.store(true);
        }
        // al_sleep_nsec(100000000); // 10 ms
        continue;
      } else {
        std::cerr << "Error reading frame" << std::endl;
        break;
      }
    }

    // check the type of packet
    if (packet->stream_index == vs->video_st_idx) {
      // send raw compressed video data in AVPacket to decoder
      if (avcodec_send_packet(vs->video_ctx, packet) < 0) {
        std::cerr << "Error sending video packet for decoding" << std::endl;
        break;
      }

      while (!vs->global_quit.load()) {
        // get decoded output data from decoder
        int ret = avcodec_receive_frame(vs->video_ctx, frame);

        // check if entire frame was decoded
        if (ret == AVERROR(EAGAIN)) {
          // need more data
          break;
        } else if (ret == AVERROR_EOF) {
          std::cerr << "EOF Error" << std::endl;
          vs->global_quit.store(true);
          break;
        } else if (ret < 0) {
          std::cerr << "Error while decoding" << std::endl;
          vs->global_quit.store(true);
          break;
        }

        // get the estimated time stamp
        double pts = frame->best_effort_timestamp;

        // if guess failed
        if (pts == AV_NOPTS_VALUE) {
          // if we don't have a pts, use the video clock
          pts = vs->video_clock;
        } else {
          // convert pts using video stream's time base
          pts *= av_q2d(vs->video_st->time_base);

          // if we have pts, set the video_clock to it
          vs->video_clock = pts;
        }

        // update video clock if frame is delayed
        vs->video_clock +=
            0.5 * av_q2d(vs->video_st->time_base) * frame->repeat_pict;

        // if (vs->video_clock < vs->master_clock) {
        //   break;
        // }

        // scale image in frame and put results in frameRGB
        // sws_scale(vs->sws_ctx, (uint8_t const *const *)frame->data,
        //           frame->linesize, 0, vs->video_ctx->height, frameRGB->data,
        //           frameRGB->linesize);

        memcpy(bufferY, frame->data[0], numBytesY);
        memcpy(bufferU, frame->data[1], numBytesU);
        memcpy(bufferV, frame->data[2], numBytesV);

        std::unique_lock<std::mutex> lk(vs->video_frames->mutex);

        // while (!vs->video_frames->put(buffer, numBytes, pts)) {
        while (!vs->video_frames->put(bufferY, numBytesY, bufferU, numBytesU,
                                      bufferV, numBytesV, pts)) {
          vs->video_frames->cond.wait_for(lk, std::chrono::milliseconds(10));

          if (vs->global_quit.load() || vs->seek_requested.load()) {
            break;
          }
        }
      }
    } else if (packet->stream_index == vs->audio_st_idx) {
      // skip if audio has been disabled
      if (!vs->audio_enabled) {
        av_packet_unref(packet);
        continue;
      }

      if (avcodec_send_packet(vs->audio_ctx, packet) < 0) {
        std::cerr << "Error sending audio packet for decoding" << std::endl;
        break;
      }

      while (!vs->global_quit.load()) {
        // get decoded output data from decoder
        int ret = avcodec_receive_frame(vs->audio_ctx, frame);

        // check if entire frame was decoded
        if (ret == AVERROR(EAGAIN)) {
          // need more data
          break;
        } else if (ret == AVERROR_EOF) {
          vs->global_quit.store(true);
          break;
        } else if (ret < 0) {
          std::cerr << "Error while decoding" << std::endl;
          vs->global_quit.store(true);
          break;
        }

        // get the estimated time stamp
        double pts = frame->best_effort_timestamp;

        // if guess failed
        if (pts == AV_NOPTS_VALUE) {
          // if we don't have a pts, use the audio clock
          pts = vs->audio_clock;
        } else {
          // convert pts using video stream's time base
          pts *= av_q2d(vs->audio_st->time_base);

          // if we have a pts, set the audio clock
          vs->audio_clock = pts;
        }

        // update audio clock if frame is delayed
        vs->audio_clock +=
            0.5 * av_q2d(vs->audio_st->time_base) * frame->repeat_pict;

        // if (vs->audio_clock < vs->master_clock) {
        //   break;
        // }

        for (int i = 0; i < vs->audio_ctx->ch_layout.nb_channels; ++i) {
          memcpy(audio_out + i * vs->audio_channel_size, frame->data[i],
                 vs->audio_channel_size);
        }

        std::unique_lock<std::mutex> lk(vs->audio_frames->mutex);

        while (!vs->audio_frames->put(audio_out, vs->audio_frame_size, pts)) {
          vs->audio_frames->cond.wait_for(lk, std::chrono::milliseconds(10));

          if (vs->global_quit.load() || vs->seek_requested.load()) {
            break;
          }
        }
      }
    }

    // wipe the packet
    av_packet_unref(packet);
  }
  // free the memory
  av_freep(&audio_out);
  av_freep(&bufferY);
  av_freep(&bufferU);
  av_freep(&bufferV);
  av_freep(&buffer);
  av_frame_free(&frameRGB);
  av_frame_free(&frame);
  av_packet_free(&packet);

  vs->global_quit.store(true);
  vs->global_finished.store(true);
}

MediaFrame *VideoDecoder::getVideoFrame(double external_clock) {
  if (!video_state.video_ctx) {
    return nullptr;
  }

  if (video_state.global_pause) {
    return nullptr;
  }

  // check if currently seeking
  if (video_state.seek_requested.load()) {
    video_buffer.cond.notify_one();
    audio_buffer.cond.notify_one();
    return nullptr;
  }

  if (delay_next_frame.load()) {
    // std::cout << "delaying" << std::endl;
    delay_next_frame = false;
    return nullptr;
  }

  // get next video frame
  video_output = video_buffer.get();
  if (!video_output) {
    return nullptr;
  }

  if (skip_next_frame.load()) {
    // std::cout << "skipping" << std::endl;
    skip_next_frame = false;
    // do {
    video_state.last_frame_pts = video_output->pts;
    video_buffer.got();
    video_output = video_buffer.get();
    if (!video_output) {
      return nullptr;
    }
    // } while (external_clock - video_state.last_frame_pts >
    // AV_SYNC_THRESHOLD);
  }

  // save pts information
  video_state.last_frame_pts = video_output->pts;

  if (video_state.master_sync == MasterSync::AV_SYNC_VIDEO) {
    // update master clock if video sync
    video_state.master_clock = video_output->pts;
  } else {
    // update master clock if external sync
    if (video_state.master_sync == MasterSync::AV_SYNC_EXTERNAL) {
      video_state.master_clock = external_clock;
    }

    // difference between target pts and current master clock
    double video_diff = video_output->pts - video_state.master_clock;
    // std::cout << video_diff << std::endl;

    // sync video if needed
    if (fabs(video_diff) > AV_NOSYNC_THRESHOLD) {
      // std::cout << "seeking" << std::endl;
      stream_seek((int64_t)(video_state.master_clock * AV_TIME_BASE),
                  -(int)video_diff);
      return nullptr;
    }

    if (video_diff > AV_SYNC_THRESHOLD) {
      delay_next_frame = true;
      skip_next_frame = false;
    } else if (video_diff < -AV_SYNC_THRESHOLD) {
      skip_next_frame = true;
      delay_next_frame = false;
    }
  }

  return video_output;
}

uint8_t *VideoDecoder::getAudioFrame(double external_clock) {
  if (video_state.global_pause.load()) {
    return nullptr;
  }

  if (video_state.seek_requested.load()) {
    return nullptr;
  }

  // get next audio frame
  audio_output = audio_buffer.get();
  if (!audio_output) {
    return nullptr;
  }

  // TODO: implement audio sync to video/external
  if (video_state.master_sync == MasterSync::AV_SYNC_AUDIO) {
    // update master clock if audio sync
    video_state.master_clock = audio_output->pts;
  }
  // else {
  //   // difference between target pts and current master clock
  //   double audio_diff = audio_output.pts - video_state.master_clock;

  //   // sync audio if needed
  //   if (fabs(audio_diff) > AV_SYNC_THRESHOLD) {
  //     std::cout << " audio_diff: " << audio_diff << std::endl;
  //   }
  // }

  return audio_output->dataY.data();
}

void VideoDecoder::stream_seek(int64_t pos, int rel) {
  if (!video_state.seek_requested.load()) {
    video_state.global_finished.store(false);

    video_state.seek_pos = pos;
    // TODO: check which flag to use
    video_state.seek_flags = (rel < 0) ? AVSEEK_FLAG_BACKWARD : 0;
    // video_state.seek_flags = AVSEEK_FLAG_ANY;
    video_state.seek_requested.store(true);

    delay_next_frame = false;
    skip_next_frame = false;

    video_buffer.cond.notify_one();
    audio_buffer.cond.notify_one();
  }
}

unsigned int VideoDecoder::audioSampleRate() {
  if (video_state.audio_ctx)
    return video_state.audio_ctx->sample_rate;
  return 0;
}

unsigned int VideoDecoder::audioNumChannels() {
  if (video_state.audio_ctx)
    return video_state.audio_ctx->ch_layout.nb_channels;
  return 0;
}

unsigned int VideoDecoder::audioSamplesPerChannel() {
  if (video_state.audio_ctx)
    return video_state.audio_ctx->frame_size;
  return 0;
}

int VideoDecoder::width() {
  if (video_state.video_ctx)
    return video_state.video_ctx->width;
  return 0;
}

int VideoDecoder::height() {
  if (video_state.video_ctx)
    return video_state.video_ctx->height;
  return 0;
}

int *VideoDecoder::lineSize() {
  if (video_state.video_ctx)
    return video_state.line_sizes;
  return nullptr;
}

double VideoDecoder::fps() {
  if (video_state.format_ctx) {
    double guess = av_q2d(av_guess_frame_rate(video_state.format_ctx,
                                              video_state.video_st, NULL));
    if (guess == 0) {
      std::cerr << "Could not guess frame rate" << std::endl;
      guess = av_q2d(video_state.format_ctx->streams[video_state.video_st_idx]
                         ->r_frame_rate);
    }
    return guess;
  }
  return 30.0f;
}

void VideoDecoder::cleanup() {
  if (video_state.audio_ctx) {
    // Close the audio codec
    avcodec_free_context(&video_state.audio_ctx);
  }
  if (video_state.video_ctx) {
    // Close the video codec
    avcodec_free_context(&video_state.video_ctx);
  }
  if (video_state.sws_ctx) {
    // free the sws context
    sws_freeContext(video_state.sws_ctx);
  }
  if (video_state.format_ctx) {
    // Close the video file
    avformat_close_input(&video_state.format_ctx);
  }
}

void VideoDecoder::stop() {
  video_state.global_quit.store(true);
  video_state.global_finished.store(true);
  video_buffer.cond.notify_one();
  audio_buffer.cond.notify_one();
  video_buffer.cond.notify_one();
  audio_buffer.cond.notify_one();

  if (decode_thread) {
    decode_thread->join();
  }
  std::thread *dth = decode_thread;
  decode_thread = nullptr;
  delete dth;

  cleanup();
  init(); // in case destructor gets called again
}
